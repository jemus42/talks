---
title: |
  A Large-Scale Neutral Comparison Study\
  of Survival Models
# subtitle: ""
author:
  - Burk, L.\inst{1,2,3,4}
  - Zobolas, J.\inst{5}
  - Bischl, B.\inst{2,4}
  - Bender, A.\inst{2,4}
  - Wright, M. N.\inst{1,3}
  - Lang, M.\inst{6}
  - Sonabend, R.\inst{7, 8}
#date: "2024-03-01"
format:
  beamer:
    template: template.tex
    widescreen: true # changes to sty now make this the only non-messed up option
    occasion: "Biometric Colloquium --- March 1st, 2024"
    email: burk@leibniz-bips.de
    themeoptions: fira
    thankstext: Thank you for your attention!
    contactauthor: Lukas Burk
    institute:
      # Can't use \inst because title frame is made with tikz and \inst doesn't work within tikz nodes
      # and \insertinstitute did not work for some other godforsaken reason, idunno
        - \textsuperscript{1}Leibniz Institute for Prevention Research and Epidemiology -- BIPS
        - \textsuperscript{2}LMU Munich \quad \textsuperscript{3}University of Bremen
        - \textsuperscript{4}Munich Center for Machine Learning (MCML)
        - \textsuperscript{5}University of Oslo \quad \textsuperscript{6} TU Dortmund
        - \textsuperscript{7}OSPO Now \quad \textsuperscript{8}Imperial College, London
    bibliography:
      - references.bib # zotero bib
      - library.bib # copypasta from overleaf
    cite-method: biblatex
    keep-tex: true
nocite: |
  @beartooth
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(ggplot2)
library(dplyr)
library(kableExtra)

knitr::opts_chunk$set(
  fig.align = "center",
  dev = "ragg_png",
  dev.args = list(bg = "transparent")
)

theme_set(
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "bottom",
    panel.spacing = unit(10, "mm"),
    plot.title.position = "plot"
  )
)

```

## Introduction

::: {.incremental}

- There are many survival learners ("models") to choose from
- Advantages and disadvantages often unclear, specific to setting
- Various comparisons exist in literature
- Limited scope (learners, tasks, evaluation measures)
- Focus on individual / new method $\Rightarrow$ no neutral comparison
- No (or limited) quantitative comparison

:::

. . .

\vspace{1em}


$\Rightarrow$ Needs _comprehensive comparison_!


## Quick Summary

- **32** tasks
- **18** learners
- **2** tuning measures
- **9** evaluation measures

\vspace{1em}

. . .

- **Large-scale** $\Rightarrow$ Generalizability
- **Neutral** $\Rightarrow$  Fair comparison

. . .

\vspace{1em}

::: {.center}

$\Rightarrow$ The _largest survival benchmark_ to date as far as we know

:::

## Scope

The _"Standard Setting"_:

\vspace{1em}

- Single-event outcome: $\delta_i \in \{0, 1\}$
- Low-dimensional: $2 \leq p < n$
- No time-varying covariates
- Right-censoring only
- At least 100 observed events

## Tasks

**32** tasks collected from R packages on CRAN

```{r task-tbl}
files = dir("~/repos/github/slds-lmu/paper_2023_survival_benchmark/code/data", pattern = "\\.rds$", 
    full.names = TRUE)
names = stringi::stri_sub(basename(files), 1, -5)
tasks = mlr3misc::named_list(names)
for (i in seq_along(files)) {
    tasks[[i]] = readRDS(files[i])
}

task_summary = data.table::rbindlist(lapply(seq_along(tasks), \(task_idx) {
  xdf = tasks[[task_idx]]
  tibble::tibble(
    task = names(tasks)[task_idx],
    N = nrow(xdf),
    p = ncol(xdf) - 2,
    `Observed Events` = sum(xdf$status == 1),
    `Cens. %` = round(100 * sum(xdf$status == 0) / nrow(xdf), 0)
  )
}))

data.table::rbindlist(lapply(seq_along(task_summary), \(i) {
  if (i == 1) return(NULL)
  x = task_summary[[i]]
  tibble::tibble(
    m = names(task_summary)[[i]],
    min = min(x),
    q25 = quantile(x, prob = 0.25),
    median = median(x),
    q75 = quantile(x, prob = 0.75),
    max = max(x)
  )
})) |>
  kbl(
    booktabs = TRUE,
    col.names = c("", "Minimum", "q25%", "Median", "q75%", "Maximum"), 
    digits = 0
  ) |>
  kable_styling() |>
  column_spec(1, bold = TRUE)
```


## Learners

**18** learners implemented in R and available via the `mlr3` [^mlr3] framework

\vspace{1em}

. . . 

::: {.incremental}

- **Baseline**: Kaplan-Meier & Nelson-Aalen
- **Classical**: Cox, penalized (L1,L2), parametric (AFT)
- **Trees**: Individuals and ensembles
- **Boosting**: Gradient- and likelihood-based
- **Other**: Akritas, SVM

:::

## List of Learners (Baseline, Classical)

```{r learners-tab-1}
tibble::tribble(
  ~Abbreviation, ~Name,                 ~`Package`,
  "KM",   "Kaplan-Meier",                "survival", 
  "NA",   "Nelson-Aalen",                "survival", 
  "CPH",  "Cox Regression",              "survival",  
  "GLM",  "Penalized Cox Regression (L1, L2)",    "glmnet",    
  "Pen",  "Penalized Cox Regression (L1, L2)",    "penalized", 
  "Par",  "Parametric (AFT)",            "survival",   
  "Flex", "Flexible Parametric Splines", "flexsurv",
  "AK",   "Akritas",                     "survivalmodels", 
  "SSVM", "Survival SVM",                "survivalsvm"
) |>
  dplyr::select(Name, Abbreviation, Package) |>
  kableExtra::kbl(booktabs = TRUE, linesep = "") |>
  kableExtra::kable_styling() |>
  kableExtra::column_spec(1, bold = TRUE) |>
  kableExtra::column_spec(3, monospace = TRUE) |>
  kableExtra::row_spec(row = 2, hline_after = TRUE) |>
  kableExtra::row_spec(row = 7, hline_after = TRUE) |>
  kableExtra::row_spec(row = 4:5, color = "#1763AA") # RColorBrewer::brewer.pal(5, "Dark2")[[1]])
```

[^mlr3]: @pkgmlr3

## List of Learners (Trees, Boosting)

```{r learners-tab-2}
tibble::tribble(
  ~Abbreviation, ~Name,                           ~Package,
 "RRT"    , "Decison Tree",                       "rpart",
 "RFSRC"  , "Random Survival Forest",             "randomForestSRC",
 "RAN"    , "Random Survival Forest",             "ranger",
 "CIF"    , "Conditional Inference Forest",       "partykit",
 "ORSF"   , "Oblique RSF",                        "aorsf",
 "MBO"    , "Model-Based Boosting",               "mboost",
 "CoxB"   , "Likelihood-Based Boosting",          "CoxBoost",
 "XGBCox" , "Gradient Boosting (Cox objective)",  "xgboost",
 "XGBAFT" , "Gradient Boosting (AFT objective)",  "xgboost"
) |>
  dplyr::select(Name, Abbreviation, Package) |>
  kableExtra::kbl(booktabs = TRUE, linesep = "") |>
  kableExtra::kable_styling() |>
  kableExtra::column_spec(1, bold = TRUE) |>
  kableExtra::column_spec(3, monospace = TRUE) |>
  kableExtra::row_spec(row = 5, hline_after = TRUE) |>
  kableExtra::row_spec(row = 2:3, color = "#1763AA")|> #RColorBrewer::brewer.pal(5, "Dark2")[[1]]) |>
  kableExtra::row_spec(row = 8:9, color = "#1763AA") #RColorBrewer::brewer.pal(5, "Dark2")[[4]])
```

<!---
## Learners (Addendum)

. . . 

> "But what about deep learning?"

. . .

::: {.incremental}

- DL learners were considered (Coxnet, DeepSurv, DNNSurv, DeepHit, ...)
- Consistent technical issues with underlying implementations
- Large computational overhead
- Poor performance expected based on literature, our experiments

:::

. . .

\vspace{2em}

$\Rightarrow$ Excluding DL in _this_ benchmark

-->

## Tuning

::: {.incremental}

- Tuning spaces discussed with learner authors
- **Resampling**: Nested cross-validation (5-fold outer, 3-fold inner)
- **Strategy**: Random Search
- **Budget**: Tuning stopped if _either_ is reached
  1. Number of evaluations: $n_{\text{evals}} = n_{\text{parameters}} \times 50$
  2. Tuning time of 150 hours ($6 \tfrac{1}{4}$ days) 
:::

<!-- ## "Well, technically..." -->

<!-- Exceptions to the previously stated rules: -->

<!-- - Some learners (`RRT`, `Par`) have small, finite search spaces $\Rightarrow$ grid search (exhaustive) -->
<!-- - Task `veteran` has few observations that we use 4 outer resampling folds to ensure at least 30 observed events per outer fold -->
<!-- - CoxBoost learner tunes itself with internal CV $\Rightarrow$ set to use 3 folds as well -->


<!-- ## Challenges -->

<!-- - Collecting all algorithms in robust benchmark would not be possible without a suitable framework such as **mlr3** -->
<!-- - Computationally only feasible thanks to support by University Wyoming and access to ARCC [@beartooth] -->
<!-- - Copious amounts of debugging, testing, trial experiments with the help of my collaborators -->

## Evaluation

::: {.incremental}

- Main Results: 
  - Friedman rank sum tests 
  - Critical difference plots[^demsar] based on Bonferroni-Dunn tests
- 3 types of metrics: Discrimination, Calibration, _Scoring Rules_
- Tuned on 2 different measures
  - Harrell's C (Discrimination)
  - Right-Censored Log Loss (Scoring Rule)

:::

[^demsar]: @Demsar2006

<!---

## Evaluation Measures

Primary evaluation measures: _Harrell's C_ and _Graf Score_

```{r eval-measures-tbl}
tibble::tribble(
  ~Abbreviation, ~Name, ~Type,
  "harrell_c", "Harrell's C",             "Discrimination",
  "uno_c",     "Uno's C",                 "Discrimination",
  "caliba",    "Van Houwelingen's Alpha", "Calibration",
  "dcalib",    "D-Calibration",           "Calibration",
  "rcll",      "Right-Censored Log Loss", "Scoring Rule",
  "graf_proper / graf_improper", "Graf Score (Proper / Improper)", "Scoring Rule",

  "intlogloss", "Integrated Log Loss (Proper)", "Scoring Rule",
  "logloss",    "Log Loss",                     "Scoring Rule",
) |>
  dplyr::select(Name, Type) |>
  kableExtra::kbl(booktabs = TRUE, linesep = "") |>
  kableExtra::kable_styling()
  # kableExtra::group_rows(start_row = 1, end_row = 2, group_label = "Discrimination") |>
  # kableExtra::group_rows(start_row = 3, end_row = 4, group_label = "Calibration") |>
  # kableExtra::group_rows(start_row = 5, end_row = 8, group_label = "Scoring Rule")
```

-->


<!-- @Avati2020 -->

# Results

```{r get-bma}
#| include: false
#| cache: true
bma = readRDS(url("https://stuff.jemu.name/survival_benchmark/results/bma_full.rds"))

bma = bma |>
  mutate(
    learner_group = case_match(learner_id,
      c("KM", "NA") ~ "Baseline",
      c("AK") ~ "Other", 
      c("CPH", "GLM", "Pen", "Par", "Flex") ~ "Classical",
      c("RRT", "RFSRC", "RAN", "CIF", "ORSF") ~ "Trees",
      c("MBO", "XGBCox", "XGBAFT", "CoxB") ~ "Boosting",
      .ptype = factor(levels = c("Baseline", "Classical", "Trees", "Boosting", "Other"))
    ),
    learner_id = factor(learner_id, levels = c(setdiff(levels(learner_id), "AK"), "AK"))
  )

palette = RColorBrewer::brewer.pal(5, "Dark2")
names(palette) = levels(bma$learner_group)

# ggsave(plot = p_box_harrell, filename = here::here("2024/02-biocoll/img/boxplot-harrell.png"), width = 10, height = 5)
# ggsave(plot = p_box_rcll, filename = here::here("2024/02-biocoll/img/boxplot-rcll.png"), width = 10, height = 5)

```


## Boxplot (Harrel's C, higher is better)

```{r boxplot-harrell}
#| fig-width: 10
#| fig-height: 5

bma |>
  dplyr::filter(tuned == "harrell_c") |>
  dplyr::filter(!(learner_id %in% c("KM", "NA"))) |>
  ggplot(aes(x = learner_id, y = harrell_c, color = learner_group, fill = learner_group)) +
  geom_boxplot(alpha = 1/4, key_glyph = "rect") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_color_manual(values = palette, aesthetics = c("color", "fill"), guide = guide_legend(keywidth = 2)) +
  # scale_color_brewer(palette = "Dark2", aesthetics = c("color", "fill"), guide = guide_legend(keywidth = 2)) +
  labs(
    #title = "Harrell's C", 
    caption = "Tuned on Harrell's C",
    x = NULL, y = "Harrell's C",
    color = NULL, fill = NULL
  ) +
  theme_minimal(base_size = 15, base_family = "Fira Sans") +
  theme(
    legend.position = "top",
    panel.background = element_rect(fill = "transparent", color = NA),
    panel.grid.major.x = element_blank()
  )
```


<!-- ```{r} -->
<!-- #| out-height: "77%" -->
<!-- # knitr::include_graphics("img/boxplot-harrell-c-1.png") -->
<!-- knitr::include_graphics("img/boxplot-harrell.png") -->

<!-- ``` -->

## Boxplot (IBS, lower is better)

```{r boxplot-ibs-rcll-full}
#| fig-width: 10
#| fig-height: 5

bma |>
  filter(brier_improper < 1) |>
  dplyr::filter(tuned == "rcll") |>
  ggplot(aes(x = learner_id, y = brier_improper, color = learner_group, fill = learner_group)) +
  geom_boxplot(alpha = 1/4, key_glyph = "rect") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_color_manual(values = palette, aesthetics = c("color", "fill"), guide = guide_legend(keywidth = 2)) +
  labs(
    #title = "Integrated Brier Score", 
    caption = "Tuned on Right-Censored Log Loss",
    x = NULL, y = "Integrated Brier Score",
    color = NULL, fill = NULL
  ) +
  theme_minimal(base_size = 15, base_family = "Fira Sans") +
  theme(
    legend.position = "top",
    panel.background = element_rect(fill = "transparent", color = NA),
    panel.grid.major.x = element_blank()
  )
```

## Boxplot (IBS, truncated)

```{r boxplot-ibs-rcll-reduced}
#| fig-width: 10
#| fig-height: 5

bma |>
  filter(brier_improper < 0.4, learner_id != "AK") |>
  ggplot(aes(x = learner_id, y = brier_improper, color = learner_group, fill = learner_group)) +
  geom_boxplot(alpha = 1/4, key_glyph = "rect") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_color_manual(values = palette, aesthetics = c("color", "fill"), guide = guide_legend(keywidth = 2)) +
  labs(
    #title = "Integrated Brier Score", 
    caption = "Tuned on Right-Censored Log Loss",
    x = NULL, y = "Integrated Brier Score",
    color = NULL, fill = NULL
  ) +
  theme_minimal(base_size = 15, base_family = "Fira Sans") +
  theme(
    legend.position = "top",
    panel.background = element_rect(fill = "transparent", color = NA),
    panel.grid.major.x = element_blank()
  )
```


## Critical Difference: Bonferroni-Dunn (Harrell's C)
<!-- Annotated --->

```{r}
#| out-height: "75%"
# knitr::include_graphics("img/critical-difference-baseline-diff-harrell-c-1.png")

# https://docs.ropensci.org/magick/reference/device.html

img = here::here("2024/02-biocoll/img/critical-difference-baseline-diff-harrell-c-1.png") |>
  magick::image_read() |>
  magick::image_annotate("Lower is better", size = 32, location = "+10+30") |>
  magick::image_draw()

rect(
  xleft = 1075, xright = 1160, 
  ybottom = 532, ytop = 220, 
  border = "red", lwd = 7
)

magick::image_write(
  image = img, 
  path = here::here("2024/02-biocoll/img/critical-difference-baseline-diff-harrell-c-1-annotated.png")
)

knitr::include_graphics("img/critical-difference-baseline-diff-harrell-c-1-annotated.png")
```

## Critical Difference: Bonferroni-Dunn (IBS/RCLL)
<!-- Annotated --->

```{r}
#| out-height: "75%"
# knitr::include_graphics("img/critical-difference-baseline-diff-rcll-7.png")


img = here::here("2024/02-biocoll/img/critical-difference-baseline-diff-rcll-7.png") |>
  magick::image_read() |>
  magick::image_annotate("Lower is better", size = 32, location = "+10+30") |>
  magick::image_draw()

rect(
  xleft = 1060, xright = 1200, 
  ybottom = 730, ytop = 220, 
  border = "red", lwd = 7
)
rect(
  xleft = 5, xright = 80, 
  ybottom = 680, ytop = 795, 
  border = "red", lwd = 7
)

magick::image_write(
  image = img, 
  path = here::here("2024/02-biocoll/img/critical-difference-baseline-diff-rcll-7-annotated.png")
)

knitr::include_graphics("img/critical-difference-baseline-diff-rcll-7-annotated.png")
```

## Closing Remarks

::: {.incremental}

- Only computationally feasible due to resources of ARCC [^beartooth]
  - Sequential runtime $\approx$ 18 years
  - Effective runtime $\approx$ 32 days
- Experimental design is not perfect, but it was _possible_ to conduct
- Results still need processing, checking, ...
- **Preliminary conclusion**: Cox regression --- hard to beat since 1972!
<!-- - The "standard setting" $\approx$ the "do you need ML?"-setting -->

:::

[^beartooth]: Advanced Research Computing Center, Beartooth Computing Environment, University of Wyoming.



<!---

## Task Table (1)

```{r}
task_summary |>
  slice(1:10) |>
  kbl(booktabs = TRUE, linesep = "") |>
  kable_styling(latex_options = c("scale_down"))
```

## Task Table (2)

```{r}
task_summary |>
  slice(11:20) |>
  kbl(booktabs = TRUE, linesep = "") |>
  kable_styling(latex_options = c("scale_down"))
```

## Task Table (3)

```{r}
task_summary |>
  slice(21:32) |>
  kbl(booktabs = TRUE, linesep = "") |>
  kable_styling(latex_options = c("scale_down"))
```

--->
