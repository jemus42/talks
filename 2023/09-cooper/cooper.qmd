---
title: |
  High-Dimensional Variable Selection\
  for Competing Risks with\
  Cooperative Penalized Regression
subtitle: "«CooPeR»"
author: 
  - Lukas Burk\inst{1,2,3,4}
  - Andreas Bender\inst{2,4}
  - Marvin N. Wright\inst{1,4}
format: 
  beamer:
    template: template.tex
    widescreen: true
    occasion: "CEN 2023"
    email: burk@leibniz-bips.de
    themeoptions: fira
    thankstext: Thank you for your attention!
    contactauthor: Lukas Burk
    institute:
      # Can't use \inst because title frame is made with tikz and \inst doesn't work within tikz nodes
      # and \insertinstitute did not work for some other godforsaken reason, idunno
        - \textsuperscript{1}Leibniz Institute for Prevention Research and Epidemiology -- BIPS
        - \textsuperscript{2}LMU Munich
        - \textsuperscript{3}University of Bremen
        - \textsuperscript{4}Munich Center for Machine Learning
    bibliography: references.bib
    cite-method: biblatex
    keep-md: true
    keep-tex: true
    # nocite: |
    #   @binder2009boostinghighdimensional
    #   @binder2008adaptingprediction
    #   @tay2023featureweighted
    #   @dyrskjot2005molecularsignature
    #   @degenhardt2019evaluationvariable
    #   @ishwaran2014randomsurvivala
---

```{r setup, include=FALSE, eval=FALSE}
library(ggplot2)
library(dplyr)
results <- readRDS("varsel-sim-results.rds")

theme_set(
  theme_minimal(base_size = 16) +
  theme(
    legend.position = "bottom", 
    panel.spacing = unit(10, "mm"), 
    plot.title.position = "plot"
  )
)
```


## Introduction

- High-dimensional survival data with two competing risks $e \in \{1, 2\}$, e.g\
    (1) Death from bladder cancer\
    (2) Death from other causes
    
. . .
    
- Common approach: 
    - Fit cause-specific model for event of interest
    - Treats other event as censored \
    $\Rightarrow$ loses information
    
. . .

**Main goal**: Fit cause-specific model for event 1 _using shared information_ from event 2

## Elastic Net


Elastic net objective function with negative log-likelihood contribution for observation $i$:

<!-- $$ -->
<!-- \hat{\beta} = \underset{\beta}{\operatorname{arg min}} \quad \mathrm{NLL}(\beta) + {\color{BIPSBlue}\lambda} \sum_{j=1}^p \left( {\color{BIPSOrange}\alpha} |\beta_j| + \frac{1 - {\color{BIPSOrange}\alpha}}{2} \beta_j^2 \right) -->
<!-- $$ -->

$$
\hat{\beta} = \underset{\beta}{\operatorname{arg min}} \quad \sum_{i=1}^n \ell(y_i, \mathbf{x}_i^\top, \symbf{\beta}) + {\color{BIPSBlue}\lambda} \sum_{j=1}^p \left( {\color{BIPSBlue}\alpha} |\beta_j| + \frac{1 - {\color{BIPSBlue}\alpha}}{2} \beta_j^2 \right)
$$

## Feature-Weighted Elastic Net


Feature-weighted elastic net [^fwe] extends the objective function:

<!-- $$ -->
<!-- \hat{\beta} = \underset{\beta}{\operatorname{arg min}} \quad \mathrm{NLL}(\beta) + {\color{BIPSBlue}\lambda} \sum_{j=1}^p \left( {\color{BIPSOrange}\alpha} |\beta_j| + \frac{1 - {\color{BIPSOrange}\alpha}}{2} \beta_j^2 \right) -->
<!-- $$ -->

$$
\hat{\beta} = \underset{\beta}{\operatorname{arg min}} \quad  \sum_{i=1}^n \ell(y_i, \mathbf{x}_i^\top, \symbf{\beta}) + \lambda \sum_{j=1}^p {\color{BIPSBlue}w_j(\theta)}\left( \alpha |\beta_j| + \frac{1 - \alpha}{2} \beta^2_j \right)
$$

. . .

$$
{\color{BIPSBlue}w_j(\theta)} = \frac{\sum_{l=1}^p \exp(\mathbf{z}_l^\top \theta)}{p \exp(\mathbf{z}_j^\top \theta)}
$$


[^fwe]: @tay2023featureweighted

<!-- ::: footnote -->
<!-- [@zou2005regularizationvariable; @tay2023featureweightedelastic] -->
<!-- ::: -->


## Feature-Weighted Elastic Net

<!-- - Motivation: Using external/prior information -->

<!-- - Adjust penalization weights on individual or groups of features -->

\begin{center}
Assign prior values / groups via matrix $\mathbf{Z} \in \mathbb{R}^{p \times K}$
\end{center}

\vspace{1em}

. . .

::: columns
::: {.column width="50%"}
Example for grouping: $\mathbf{Z} \in \mathbb{R}^{5 \times 2}$

$$
\mathbf{Z} = 
\begin{pmatrix} 
1 & 0 \\
1 & 0 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
\end{pmatrix}
$$
:::

. . .

::: {.column width="50%"}
...and individual weighting: $\mathbf{Z} \in \mathbb{R}^{5 \times 1}$
$$
\mathbf{Z} = 
\begin{pmatrix} 
1.5 \\
1 \\
1.2 \\
0.7 \\
0.3 \\
\end{pmatrix}
$$
:::
:::

## Feature-Weighted Elastic Net


$$
w_j(\theta) = \frac{\sum_{l=1}^p \exp(\mathbf{z}_l^\top \theta)}{p \exp(\mathbf{z}_j^\top \theta)}
$$

\vspace{1em}

-   $\theta \in \mathbb{R}^{K \times 1}$ selected internally

-   $\mathbf{z}_j^\top \theta$: "Importance score"

-   Larger value $\Rightarrow$ lower $w_j$

-   $\theta = 0 \Rightarrow w_j = 1$


::: columns
::: {.column width="50%"}

:::


::: {.column width="50%"}

:::

:::

## Individual Feature Weighting

<!-- -   $\mathbf{Z} \in \mathbb{R}^{p \times 1}$: Individual weights -->
-   Simulation from Tay et al.: $\mathbf{Z}$ set to noisy version of true $|\symbf{\beta}|$
-   $|\beta_j|$ large $\Rightarrow$ weaker penalization for $\hat{\beta}_j$
-   $|\beta_j|$ small $\Rightarrow$ stronger penalization for $\hat{\beta}_j$


## Application for Multi-Task Learning

Tay et al. suggest algorithm given $\mathbf{X}$ and targets $\mathbf{y}_1, \mathbf{y}_2$:

\vspace{1em}

. . .

1.  Set $\symbf{\hat{\beta}}_1^{(0)}, \symbf{\hat{\beta}}_2^{(0)}$ to elastic net solution for $(\mathbf{X}, \mathbf{y}_1), (\mathbf{X}, \mathbf{y}_2)$

. . .

2.  For $k = 0, 1, \ldots$ until stopped:

  <!-- a)  $\mathbf{Z}_2 = \left|\symbf{\beta}_1^{(k)}\right|$. Fit $\operatorname{fwelnet}(\mathbf{X}, \mathbf{y}_2, \mathbf{Z}_2)$ to determine $\left|\symbf{\beta}_2^{(k+1)}\right|$ -->

  a) Fit $\operatorname{fwelnet}\left(\mathbf{X}, \mathbf{y}_2, \mathbf{Z}_2 = \left|\symbf{\hat{\beta}}_1^{(k)}\right|\right)$ to determine $\left|\symbf{\hat{\beta}}_2^{(k+1)}\right|$

. . .

  b) Fit $\operatorname{fwelnet}\left(\mathbf{X}, \mathbf{y}_1, \mathbf{Z}_1 = \left|\symbf{\hat{\beta}}_2^{(k+1)}\right|\right)$ to determine $\left|\symbf{\hat{\beta}}_1^{(k+1)}\right|$

## Transfer to Competing Risks



::: incremental
-   Adapt previous algorithm to Cox regression: $\mathbf{y}_e \Rightarrow (\mathbf{t}_e, \delta_e)$
-   Assumption: Shared information between both events
-   $X_j$ important for cause 1 $\Rightarrow$ relevant for cause 2? \
    $\Rightarrow$ lower $\beta_j$ penalty in cause-specific models
<!-- -   Multi-task $\simeq$ "Multi-cause" -->
:::

\vspace{1em}

. . .

\begin{center}
{\large Dubbed "Cooperative Penalized (Cox) Regression" (\strong{\blue{CooPeR}})}
\end{center}

## Simulation Study

::: incremental
- Simulation setup adapted from from Binder et al.[^binder]
- Mimics gene expression data with competing risk target
- n = 400, p = 5000, 4 covariate blocks, 4 informative each
    <!-- - 250 variables per block, 4 informative each -->
<!-- - Use $\mathbf{1}\{\hat{\beta}_j \neq 0\}$ as classification decision -->
- Comparison with CoxBoost[^cb], Random Survival Forests [^rsf]
:::

[^binder]: @binder2009boostinghighdimensional
[^rsf]: @ishwaran2014randomsurvivala
[^cb]: @binder2008adaptingprediction

## Assignment of True Effects

::: incremental
- Block 1 (**Mutual**): Same effect on both cause-specific hazards
- Block 2 (**Reversed**): Positive cause 1, negative on cause 2
- Block 3 (**Disjoint**):
    - 3.1: effect on cause 1 only
    - 3.2: effect on cause 2 only
:::

. . .

- Block 4 (**Cor. Noise**): 500 variables
- Remaining variables: Uncorrelated noise


## Positive Predictive Value
\framesubtitle{Probability a selected variable is informative}
<!-- $\tfrac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}$ -->


```{r}
#| fig-align: "center"
#| out-height: "70%"
#| out-width: "85%"
# fig-asp: 1
knitr::include_graphics("img/cen-selected-ppv-equallambda.pdf")
```

## False Positive Rate 
\framesubtitle{Proportion of noise variables falsely selected}
<!-- $\tfrac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}}$ -->


```{r}
#| out-height: "70%"
#| out-width: "90%"
#| fig-align: "center"
# fig-asp: 1
knitr::include_graphics("img/cen-selected-fpr-equallambda.pdf")
```

<!-- ::: footer -->
<!-- $$\mathrm{FPR} = \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}} = 1 - \mathrm{TNR}$$ -->
<!-- ::: -->


## Application on Bladder Cancer Data

::: incremental
- Clinical & gene expression features [^bladder]

- Procedure:
    1. Apply algorithms for variable selection
    2. Fit standard cause-specific Cox model using only selected variables
    3. Evaluate prediction performance (Brier(t), AUC(t))

- Results: 
  - CooPeR-selected variables mostly identical to pen. Cox regression
  - Difference in metrics far from conclusive in either direction
:::

[^bladder]: @dyrskjot2005molecularsignature


## Conclusion & Outlook

::: incremental
- Promising variable selection behavior in simulations

- So far no promising results on real data

- Lack of widely available high-dimensional data with competing risks

- Generalization for $e > 2$ causes unclear
:::

